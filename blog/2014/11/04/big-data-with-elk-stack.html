

<!-- Nice to see you took a peek here, hello -->
<!-- send us an email at hello at brewhouse dot io if you want to talk tech -->

<!DOCTYPE html>
<!--[if lt IE 7 ]> <html class="ie6" lang="en"> <![endif]-->
<!--[if IE 7 ]>    <html class="ie7" lang="en"> <![endif]-->
<!--[if IE 8 ]>    <html class="ie8" lang="en"> <![endif]-->
<!--[if IE 9 ]>    <html class="ie9" lang="en"> <![endif]-->
<!--[if (gt IE 9)|!(IE)]><!--> <html lang="en"> <!--<![endif]-->

<html lang="en-us" class="blog">
  <head prefix="og: http://ogp.me/ns# fb: http://ogp.me/ns/fb# business: http://ogp.me/ns/business#">

    <title>Big data in minutes with the ELK Stack</title>
    <meta property="og:title" content="Big data in minutes with the ELK Stack">
    <meta property="og:site_name" content="brewhouse">
    <meta property="og:url" content="http://brewhouse.io/blog/2014/11/04/big-data-with-elk-stack.html">

    <meta property="og:image" content="http://brewhouse.io/images/posts/2014/Nov/bigdata.png">

    <meta property="twitter:card" content="summary" />
    <meta property="twitter:site" content="@brewhouseteam" />
    <meta property="twitter:image" content="http://brewhouse.io/images/posts/2014/Nov/bigdata.png">
    <meta property="twitter:url" content="http://brewhouse.io/blog/2014/11/04/big-data-with-elk-stack.html">

    <link rel="alternate" type="application/atom+xml" href="/blog/index.xml" title="The Brew Pub atom feed">

    
      <meta property="og:type" content="article">
      <meta property="article:published_time" content="2014-11-04">
      <meta property="article:tag" content="Philippe Creux">

      <meta property="twitter:title" content="Big data in minutes with the ELK Stack">

      
        <meta name="description" content="We here at Brewhouse have built a data analysis and dashboarding infrastucture for one of our clients over the past few weeks. They collect about 10 million data points a day ...">
        <meta property="twitter:description" content="We here at Brewhouse have built a data analysis and dashboarding infrastucture for one of our clients over the past few weeks. They collect about 10 million data points a day ...">
        <meta property="og:description" content="We here at Brewhouse have built a data analysis and dashboarding infrastucture for one of our clients over the past few weeks. They collect about 10 million data points a day ...">
      
    

    <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">

<meta name="robots" content="INDEX, FOLLOW">

<link rel="shortcut icon" href="/images/icons/favicon.ico" type="image/x-icon">
<link rel="apple-touch-icon" href="/images/icons/apple-touch-icon.png">
<link rel="apple-touch-icon" sizes="57x57" href="/images/icons/apple-touch-icon-57x57.png">
<link rel="apple-touch-icon" sizes="72x72" href="/images/icons/apple-touch-icon-72x72.png">
<link rel="apple-touch-icon" sizes="76x76" href="/images/icons/apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" sizes="114x114" href="/images/icons/apple-touch-icon-114x114.png">
<link rel="apple-touch-icon" sizes="120x120" href="/images/icons/apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" sizes="144x144" href="/images/icons/apple-touch-icon-144x144.png">
<link rel="apple-touch-icon" sizes="152x152" href="/images/icons/apple-touch-icon-152x152.png">

<link rel="stylesheet" href="/assets/application-839dfef25ad39261314a01bb139b4d4c.css">

  </head>
  <body class="on-post">
    <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-46725009-2', 'brewhouse.io');
  ga('send', 'pageview');

</script>


    <nav id="navbar-blog" class="navbar navbar-default navbar-main" role="navigation">
      <a id="brewhouse-logo" class="navbar-brand internal" rel="home" href="/" title="brewhouse logo"><img src="/images/brewhouse-logo-blog-2.png"></a>
    </nav>

    <div class="container main">
      <div class="body-border-top">
</div>
<div id="banner-blog" class="row">
  <div class="banner-content">
    <section class="col-xs-12 col-sm-5">
      <h1 id="brew-pub-start">
        <a href="/blog/"><img src="/images/blog-brew-pub-logo.png"></a>
      </h1>
      <h3>
        Writings from <a href="http://brewhouse.io">brewhouse.io</a>, makers of <a href="https://goodbits.io?utm_source=brewhouse-blog">Goodbits</a> and superb apps for our clients.
      </h3>
    </section>
    <section class="col-xs-12 col-sm-4">
      <p class="blog-contact-info">
        email <a href="mailto:hello@brewhouse.io">hello@brewhouse.io</a>
        <br>or, give us a call <a class="telephone" href="tel:+16046147784">+1 604-757-4242</a>
      </p>
    </section>
  </div>
</div>


      

<div id="article-start" class="content">
  <div class="row">
    <div class="col-xs-12 col-sm-9">

      <div class="post">
        <div class="social-actions">
          <a href="https://twitter.com/share?via=BrewhouseTeam" class="twitter-share-button" data-lang="en" data-url="http://brewhouse.io/blog/2014/11/04/big-data-with-elk-stack.html" data-related="chancancode,kalv,pcreux,chuckbergeron" data-counturl="">Tweet</a>
        </div>

        <h1>
          Big data in minutes with the ELK Stack
        </h1>
        <p class="meta">
          
            <span>
              <img class="img-circle img-author" src="//www.gravatar.com/avatar/cf8db14764d6420698b0ed9c9ed1ba93?s=135" alt="A photo of Philippe Creux" width="55">

              <a href="http://twitter.com/pcreux" target="_blank">Philippe Creux</a> wrote this on 04 Nov 2014
            </span>
          
        </p>

        <p>We’ve built a data analysis and dashboarding infrastructure for one of our clients over the past few weeks. They collect about 10 million data points a day. Yes, that’s big data.</p>

<p>My highest priority was to allow them to browse the data they collect so that they can ensure that the data points are consistent and contain all the attributes required to generate the reports and dashboards they need.</p>

<p>I chose to give the <a href="http://www.elasticsearch.org/overview/">ELK stack</a> a try: <a href="http://www.elasticsearch.org/overview/elasticsearch/">ElasticSearch</a>, <a href="http://www.elasticsearch.org/overview/logstash/">logstash</a> and <a href="http://www.elasticsearch.org/overview/kibana/">Kibana</a>.</p>

<!-- break -->

<p><a href="http://www.elasticsearch.org/overview/elasticsearch/">ElasticSearch</a> is a schema-less database that has powerful search capabilities and is easy to scale horizontally. Schema-less means that you just throw JSON at it and it updates the schema as you go. It indexes every single field, so you can search anything (with full-text search) and it will aggregate and group the data. Registering a new node to a cluster is a matter of installing ElasticSearch on a machine and editing a config file. ElasticSearch takes care of spreading data around and splitting out requests over multiple servers.</p>

<p><a href="http://www.elasticsearch.org/overview/logstash/">logstash</a> allows you to pipeline data to and from anywhere. This is called an ETL (for Extract, Transform, Load) pipeline in the Business Intelligence and Data warehousing world, and it is what allows us to fetch, transform, and store events into ElasticSearch.</p>

<p><a href="http://www.elasticsearch.org/overview/kibana/">Kibana</a> is a web-based data analysis and dashboarding tool for ElasticSearch. It leverages ElasticSearch’s search capabilities to visualise your (big) data in seconds.</p>

<p><img src="/images/posts/2014/Nov/flow.jpg" alt="flow" /></p>

<h2 id="logstash-etl-pipeline-made-simple"><em>logstash</em>: ETL pipeline made simple</h2>

<p><em>logstash</em> is a simple tool that streams data from one or many inputs, transforms it and outputs it to one or many outputs.</p>

<h3 id="inputs-read-and-parse-data">Inputs: read and parse data</h3>

<p>Inputs are data sources such as log files (<code>/var/log/*.log</code>) or data stored in a <em>S3 bucket</em>, <em>RabbitMQ</em>, <em>redis</em>, etc. Once the raw data is read, <em>logstash</em> parses it using codecs such as <em>JSON</em>, <em>key=value</em>, <em>graphite format</em> etc. You can find a <a href="http://logstash.net/docs/1.4.2/">full list of inputs and codecs</a> on <a href="http://logstash.net/docs/1.4.2/"><em>logstash</em> documentation</a>.</p>

<p>Let’s write a <em>logstash</em> configuration file to load data from an S3 bucket containing text files with one JSON blob per line.</p>

<div class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="c1"># logstash.conf</span>

<span class="n">input</span> <span class="p">{</span>
  <span class="n">s3</span> <span class="p">{</span>
    <span class="n">bucket</span> <span class="o">=&gt;</span> <span class="s2">&quot;my-bucket&quot;</span>
    <span class="n">credentials</span> <span class="o">=&gt;</span> <span class="o">[</span> <span class="s2">&quot;aws-key&quot;</span><span class="p">,</span> <span class="s2">&quot;aws-token&quot;</span> <span class="o">]</span>
    <span class="n">codec</span> <span class="o">=&gt;</span> <span class="s2">&quot;json&quot;</span>
  <span class="p">}</span>
<span class="p">}</span></code></pre></div>

<h3 id="filters-transform-and-extend-data">Filters: transform and extend data</h3>

<p>We now have data in the <em>logstash</em> pipeline. It’s time to transform it a little. Take this sample input file:</p>

<div class="highlight"><pre><code class="language-json" data-lang="json"><span class="err">//</span> <span class="err">s</span><span class="mi">3</span><span class="err">://my-bucket/input</span><span class="mi">-1</span><span class="err">.txt</span>

<span class="p">{</span> <span class="nt">&quot;action&quot;</span><span class="p">:</span><span class="s2">&quot;start game&quot;</span><span class="p">,</span> <span class="nt">&quot;user&quot;</span><span class="p">:</span><span class="s2">&quot;bob&quot;</span><span class="p">,</span>  <span class="nt">&quot;time&quot;</span><span class="p">:</span><span class="mi">123456789</span><span class="p">,</span> <span class="err">ip:</span><span class="nt">&quot;56.42.42.42&quot;</span>  <span class="p">}</span>
<span class="p">{</span> <span class="nt">&quot;action&quot;</span><span class="p">:</span><span class="s2">&quot;win game&quot;</span><span class="p">,</span>   <span class="nt">&quot;user&quot;</span><span class="p">:</span><span class="s2">&quot;kale&quot;</span><span class="p">,</span> <span class="nt">&quot;time&quot;</span><span class="p">:</span><span class="mi">123456792</span><span class="p">,</span> <span class="err">ip:</span><span class="nt">&quot;134.26.26.26&quot;</span> <span class="p">}</span>

<span class="err">...</span></code></pre></div>

<p>We can get <em>logstash</em> to generate a proper <em>@timestamp</em> field (later used by Kibana) and to add geolocalization using the IP address with the following filters:</p>

<div class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="c1"># logstash.conf</span>

<span class="n">input</span> <span class="p">{</span>
  <span class="c1"># ...</span>
<span class="p">}</span>

<span class="n">filter</span> <span class="p">{</span>
  <span class="c1"># Parse the `time` attribute as a UNIX timestamp (seconds since epoch)</span>
  <span class="c1"># and store it in `@timestamp` attribute. This will be used in Kibana later on.</span>
  <span class="n">date</span> <span class="p">{</span>
    <span class="n">match</span> <span class="o">=&gt;</span> <span class="o">[</span> <span class="s2">&quot;time&quot;</span><span class="p">,</span> <span class="s2">&quot;UNIX&quot;</span> <span class="o">]</span>
  <span class="p">}</span>

  <span class="c1"># Add geolocalization attributes based on ip.</span>
  <span class="n">geoip</span> <span class="p">{</span>
    <span class="n">source</span> <span class="o">=&gt;</span> <span class="s2">&quot;ip&quot;</span>
  <span class="p">}</span>
<span class="p">}</span></code></pre></div>

<h3 id="output-load-data">Output: load data</h3>

<p>The output section is quite similar to the input one. You can output to stdout (handy for debugging purpose or to pipe into another command) as well as storing on S3, loading into a database such as ElasticSearch etc.</p>

<p>Let’s output to stdout using the <code>ruby-debug</code> format:</p>

<div class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">input</span> <span class="p">{</span>
  <span class="c1"># ...</span>
<span class="p">}</span>

<span class="n">filter</span> <span class="p">{</span>
  <span class="c1"># ...</span>
<span class="p">}</span>

<span class="n">output</span> <span class="p">{</span>
  <span class="n">stdout</span> <span class="p">{</span>
    <span class="n">codec</span> <span class="o">=&gt;</span> <span class="n">ruby</span><span class="o">-</span><span class="n">debug</span>
  <span class="p">}</span>
<span class="p">}</span></code></pre></div>

<p>and run <em>logstash</em> to ensure that everything is wound up properly:</p>

<div class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="c1"># $&gt; logstash -f logstash.conf</span>


<span class="p">{</span>
        <span class="s2">&quot;action&quot;</span> <span class="o">=&gt;</span> <span class="s2">&quot;start game&quot;</span><span class="p">,</span>
          <span class="s2">&quot;user&quot;</span> <span class="o">=&gt;</span> <span class="s2">&quot;bob&quot;</span><span class="p">,</span>
          <span class="s2">&quot;time&quot;</span> <span class="o">=&gt;</span> <span class="mi">123456789</span><span class="p">,</span>
            <span class="s2">&quot;ip&quot;</span> <span class="o">=&gt;</span> <span class="s2">&quot;56.42.42.42&quot;</span><span class="p">,</span>
      <span class="s2">&quot;@version&quot;</span> <span class="o">=&gt;</span> <span class="s2">&quot;1&quot;</span><span class="p">,</span>
    <span class="s2">&quot;@timestamp&quot;</span> <span class="o">=&gt;</span> <span class="s2">&quot;1973-11-29T21:33:09.000Z&quot;</span><span class="p">,</span>
          <span class="s2">&quot;path&quot;</span> <span class="o">=&gt;</span> <span class="s2">&quot;s3://my-bucket/input-1.txt&quot;</span><span class="p">,</span>
         <span class="s2">&quot;geoip&quot;</span> <span class="o">=&gt;</span> <span class="p">{</span>
                      <span class="s2">&quot;ip&quot;</span> <span class="o">=&gt;</span> <span class="s2">&quot;56.42.42.42&quot;</span><span class="p">,</span>
           <span class="s2">&quot;country_code2&quot;</span> <span class="o">=&gt;</span> <span class="s2">&quot;US&quot;</span><span class="p">,</span>
           <span class="s2">&quot;country_code3&quot;</span> <span class="o">=&gt;</span> <span class="s2">&quot;USA&quot;</span><span class="p">,</span>
            <span class="s2">&quot;country_name&quot;</span> <span class="o">=&gt;</span> <span class="s2">&quot;United States&quot;</span><span class="p">,</span>
          <span class="s2">&quot;continent_code&quot;</span> <span class="o">=&gt;</span> <span class="s2">&quot;NA&quot;</span><span class="p">,</span>
             <span class="s2">&quot;region_name&quot;</span> <span class="o">=&gt;</span> <span class="s2">&quot;NC&quot;</span><span class="p">,</span>
               <span class="s2">&quot;city_name&quot;</span> <span class="o">=&gt;</span> <span class="s2">&quot;Raleigh&quot;</span><span class="p">,</span>
             <span class="s2">&quot;postal_code&quot;</span> <span class="o">=&gt;</span> <span class="s2">&quot;27668&quot;</span><span class="p">,</span>
                <span class="s2">&quot;latitude&quot;</span> <span class="o">=&gt;</span> <span class="mi">35</span><span class="o">.</span><span class="mi">79769999999999</span><span class="p">,</span>
               <span class="s2">&quot;longitude&quot;</span> <span class="o">=&gt;</span> <span class="o">-</span><span class="mi">78</span><span class="o">.</span><span class="mi">6253</span><span class="p">,</span>
                <span class="s2">&quot;dma_code&quot;</span> <span class="o">=&gt;</span> <span class="mi">560</span><span class="p">,</span>
               <span class="s2">&quot;area_code&quot;</span> <span class="o">=&gt;</span> <span class="mi">919</span><span class="p">,</span>
                <span class="s2">&quot;timezone&quot;</span> <span class="o">=&gt;</span> <span class="s2">&quot;America/New_York&quot;</span><span class="p">,</span>
        <span class="s2">&quot;real_region_name&quot;</span> <span class="o">=&gt;</span> <span class="s2">&quot;North Carolina&quot;</span><span class="p">,</span>
                <span class="s2">&quot;location&quot;</span> <span class="o">=&gt;</span> <span class="o">[</span>
            <span class="o">[</span><span class="mi">0</span><span class="o">]</span> <span class="o">-</span><span class="mi">78</span><span class="o">.</span><span class="mi">6253</span><span class="p">,</span>
            <span class="o">[</span><span class="mi">1</span><span class="o">]</span> <span class="mi">35</span><span class="o">.</span><span class="mi">79769999999999</span>
        <span class="o">]</span>
    <span class="p">}</span>
<span class="p">}</span>
<span class="c1"># ...</span></code></pre></div>

<p>Nice, all attributes were parsed properly and we now have <em>@timestamp</em> and <em>geoip</em> attributes.</p>

<p>Our final configuration file looks like this:</p>

<div class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">input</span> <span class="p">{</span>
  <span class="n">s3</span> <span class="p">{</span>
    <span class="n">bucket</span> <span class="o">=&gt;</span> <span class="s2">&quot;my-bucket&quot;</span>
    <span class="n">credentials</span> <span class="o">=&gt;</span> <span class="o">[</span> <span class="s2">&quot;my-aws-key&quot;</span><span class="p">,</span> <span class="s2">&quot;my-aws-token&quot;</span> <span class="o">]</span>
    <span class="n">region_endpoint</span> <span class="o">=&gt;</span> <span class="s2">&quot;us-east-1&quot;</span>
    <span class="c1"># keep track of the last processed file</span>
    <span class="n">sincedb_path</span> <span class="o">=&gt;</span> <span class="s2">&quot;./last-s3-file&quot;</span>
    <span class="n">codec</span> <span class="o">=&gt;</span> <span class="s2">&quot;json&quot;</span>
  <span class="p">}</span>
<span class="p">}</span>

<span class="n">filter</span> <span class="p">{</span>
  <span class="c1"># set the event timestamp</span>
  <span class="n">date</span> <span class="p">{</span>
    <span class="n">match</span> <span class="o">=&gt;</span> <span class="o">[</span> <span class="s2">&quot;time&quot;</span><span class="p">,</span> <span class="s2">&quot;UNIX&quot;</span> <span class="o">]</span>
  <span class="p">}</span>

  <span class="c1"># add geoip attributes</span>
  <span class="n">geoip</span> <span class="p">{</span>
    <span class="n">source</span> <span class="o">=&gt;</span> <span class="s2">&quot;ip&quot;</span>
  <span class="p">}</span>
<span class="p">}</span>


<span class="n">output</span> <span class="p">{</span>
  <span class="n">elasticsearch_http</span> <span class="p">{</span>
    <span class="n">host</span> <span class="o">=&gt;</span> <span class="s2">&quot;localhost&quot;</span>
    <span class="n">port</span> <span class="o">=&gt;</span> <span class="s2">&quot;9200&quot;</span>
  <span class="p">}</span>
<span class="p">}</span></code></pre></div>

<p>There is quite a lot going on in just a few lines of code, eh?</p>

<p>On top of this, <em>logstash</em> keeps track of the inputs it has processed. So you can restart it without being concerned of data duplication.</p>

<p>Although <em>logstash</em> is written in <em>Ruby</em>, it is really fast. The packaged version runs on <em>JRuby</em> and it takes advantage of the JVM’s threading capabilities by throwing dozens of threads to parallelize data processing.</p>

<h2 id="elasticsearch--kibana">ElasticSearch &amp; Kibana</h2>

<p><em>logstash</em> is now ready to store data in <em>ElasticSearch</em>. Getting ElasticSearch running on your machine <a href="http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/setup.html">takes minutes</a>. <a href="http://www.elasticsearch.org/overview/kibana/installation/">Setup Kibana</a>. A couple of clicks later, you’ve got a good looking dashboard.</p>

<p><img src="/images/posts/2014/Nov/kibana.jpg" alt="kibana-dashboard" /></p>

<h3 id="setting-this-up-in-production">Setting this up in production</h3>

<p>There is an excellent <a href="https://github.com/lusis/chef-logstash">chef cookbook</a> to deploy <em>logstash</em> in minutes.</p>

<p>We decided to use a hosted solution to manage the ElasticSearch cluster. The top two seem to be <a href="http://qbox.io">qbox.io</a> and <a href="http://found.no">found.no</a>. <a href="http://found.no">found.no</a> provides reserved instances and allows you to scale your cluster without any downtime.</p>

<p>Kibana comes as a plugin on all hosted ElasticSearch services, so you just have to tick a checkbox and you’re ready to go!</p>

<p>Performance wise, an ElasticSearch cluster with 4x <a href="http://aws.amazon.com/ec2/instance-types/#Compute_Optimized">Amazon EC2 c3.xlarge</a> is sufficient to run Kibana reports on the last 30 days. This is about 3 billion data entries.</p>

<h2 id="elk---to-store-and-visualize-huge-amounts-of-data-in-minutes">ELK - to store and visualize huge amounts of data in minutes</h2>

<p><em>logstash</em> enabled us to deliver an ETL pipeline that is highly performant, reliable and easy to maintain in a matter of hours. <em>Elastic Search</em> is a no brainer database that ingests anything you throw at it and scales horizontally when need be. <em>Kibana</em> allows you to make sense of your data and publish dashboards in minutes. I recommend you giving it a try to these powerful and simple tools.</p>

<p>Kibana 4 is on the way, and a final version should be released in the next couple of months. It provides new features to generate business-oriented reports such as unique counts, funnels, etc. Until then, and to report on years of data, we’ve implemented a pipeline to load data into the data warehouse solution <a href="http://aws.amazon.com/redshift/">Amazon Redshift</a>. But this is a whole other story.</p>

<p>If this is a project you’re working on and would like some help with, reach out for a chat!</p>


        <div class="mailchimp-form text-center">
          <p>
            Stay up to date with us here at the BrewPub:
          </p>
          <!-- Begin MailChimp Signup Form -->
          <link href="//cdn-images.mailchimp.com/embedcode/slim-081711.css" rel="stylesheet" type="text/css">
          <div id="mc_embed_signup" class="row">
            <form action="http://brewhouse.us8.list-manage.com/subscribe/post?u=c524f6473f5901cae1230a052&amp;id=14f9de4be1" method="post" id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" class="validate" target="_blank" novalidate>

              <div class="col-sm-offset-1 col-sm-6">
                <input type="email" value="" name="EMAIL" class="email" id="mce-EMAIL" placeholder="your email address" required style="width: 100%; margin: 0 0 4% 0">
              </div>
              <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->
              <div style="position: absolute; left: -5000px;">
                <input type="text" name="b_c524f6473f5901cae1230a052_14f9de4be1" value="">
              </div>

              <div class="col-sm-4 subscribe-button">
                <input type="submit" value="SIGN UP NOW" name="subscribe" id="mc-embedded-subscribe" class="button">
              </div>
            </form>
          </div>
          <!--End mc_embed_signup-->
        </div>

        <div id="disqus_thread"></div>

        <!-- disqus -->
        <script type="text/javascript">
            var disqus_shortname = 'brewhouse';
            var disqus_url = 'http://brewhouse.io/blog/2014/11/04/big-data-with-elk-stack.html';

            (function() {
                var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
                dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
                (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
            })();
        </script>
        <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
        <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
        <!-- /disqus -->

      </div><!-- /post -->

    </div>
  </div><!-- /row -->
</div><!-- /content-->

<script>
  !function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0];if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src="https://platform.twitter.com/widgets.js";fjs.parentNode.insertBefore(js,fjs);}}(document,"script","twitter-wjs");
</script>

    </div>

    <footer>
      <div class="container">
        <div class="row">
          <section class="col-xs-11 col-xs-offset-1">
            <p class="blog-contact-info">
              email <a href="mailto:hello@brewhouse.io">hello@brewhouse.io</a>
              <br>or, give us a call <a class="telephone" href="tel:+16046147784">+1 604-757-4242</a>
            </p>
          </section>
        </div>
        <div class="row">
          <div class="col-xs-11 col-xs-offset-1">
            <p>
              &copy; <span class="copyright-year"></span> <a href="http://brewhouse.io">brewhouse software, inc.</a>
            </p>
          </div><!--col-xs-12 -->
        </div><!-- row -->
      </div><!-- container -->
    </footer>

    <script src="/assets/app-3daea0c377e49bb0b1319eb4c55ccbd6.js"></script>
  </body>
</html>
